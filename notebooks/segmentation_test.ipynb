{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8ebb0420",
   "metadata": {},
   "source": [
    "Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05222f8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "PROJECT_ROOT = Path(\"..\").resolve()\n",
    "\n",
    "DATA_DIR = PROJECT_ROOT / \"data\" / \"Converted Images\"\n",
    "\n",
    "ANNOT_DIR = PROJECT_ROOT / \"data\" / \"Annotated Files\"\n",
    "\n",
    "OUT_DIR = PROJECT_ROOT / \"outputs\"\n",
    "SAMPLE_DIR = OUT_DIR / \"samples\" / \"segmentation_guided\"\n",
    "SAMPLE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "EXTS = {\".jpg\", \".jpeg\", \".png\", \".bmp\"}\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "\n",
    "FIXED_SIZE = (300, 300)  # (W, H)\n",
    "\n",
    "def read_bgr_300(path):\n",
    "    \"\"\"Read color image and resize to 300x300 using bilinear interpolation (paper).\"\"\"\n",
    "    bgr = cv2.imread(str(path))\n",
    "    if bgr is None:\n",
    "        return None\n",
    "    return cv2.resize(bgr, FIXED_SIZE, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "def read_gray_300(path):\n",
    "    \"\"\"Read grayscale image and (safely) resize to 300x300.\"\"\"\n",
    "    gray = cv2.imread(str(path), cv2.IMREAD_GRAYSCALE)\n",
    "    if gray is None:\n",
    "        return None\n",
    "    return cv2.resize(gray, FIXED_SIZE, interpolation=cv2.INTER_LINEAR)\n",
    "\n",
    "INDEX_CSV = OUT_DIR / \"preprocessed_index.csv\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "205dc1c3",
   "metadata": {},
   "source": [
    "Test Annotated files (Normalized?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcf78b4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample txt: E:\\Kuliah\\Pengenalan Pola\\addressing_agricultural_challenges\\data\\Annotated Files\\Anthracnose (1).txt\n",
      "First line: 1 0.456067 0.766338 0.324639 0.331689\n",
      "Parsed: [1.0, 0.456067, 0.766338, 0.324639, 0.331689]\n",
      "=> Format: YOLO normalized (aman untuk resize berapapun)\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "txt_path = next(ANNOT_DIR.rglob(\"*.txt\"))\n",
    "print(\"Sample txt:\", txt_path)\n",
    "\n",
    "with open(txt_path, \"r\") as f:\n",
    "    line = f.readline().strip()\n",
    "print(\"First line:\", line)\n",
    "\n",
    "parts = line.split()\n",
    "nums = list(map(float, parts))\n",
    "print(\"Parsed:\", nums)\n",
    "\n",
    "# cek apakah (xc,yc,w,h) berada di 0..1\n",
    "if len(nums) == 5 and all(0.0 <= v <= 1.0 for v in nums[1:]):\n",
    "    print(\"=> Format: YOLO normalized (aman untuk resize berapapun)\")\n",
    "else:\n",
    "    print(\"=> Kemungkinan pixel coords / format lain (perlu scaling)\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b5c533d",
   "metadata": {},
   "source": [
    "Scan Dataset & Binary Labeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "699f6bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded: E:\\Kuliah\\Pengenalan Pola\\addressing_agricultural_challenges\\outputs\\preprocessed_index.csv\n",
      "Rows: 724\n",
      "Counts per class:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "class\n",
       "Healthy            136\n",
       "Soft_Rot           129\n",
       "Gray_Blight        119\n",
       "Brown_Stem_Spot    119\n",
       "Anthracnose        118\n",
       "Stem_Canker        103\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Binary counts (Output):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Output\n",
       "1    588\n",
       "0    136\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>orig_path</th>\n",
       "      <th>prep_path</th>\n",
       "      <th>class</th>\n",
       "      <th>Output</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>resize_mode</th>\n",
       "      <th>gaussian</th>\n",
       "      <th>gamma</th>\n",
       "      <th>equalization</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>E:\\Kuliah\\Pengenalan Pola\\addressing_agricultu...</td>\n",
       "      <td>E:\\Kuliah\\Pengenalan Pola\\addressing_agricultu...</td>\n",
       "      <td>Anthracnose</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>fixed300_bilinear</td>\n",
       "      <td>(5, 5)_sigma0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>hist_eq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>E:\\Kuliah\\Pengenalan Pola\\addressing_agricultu...</td>\n",
       "      <td>E:\\Kuliah\\Pengenalan Pola\\addressing_agricultu...</td>\n",
       "      <td>Anthracnose</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>fixed300_bilinear</td>\n",
       "      <td>(5, 5)_sigma0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>hist_eq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>E:\\Kuliah\\Pengenalan Pola\\addressing_agricultu...</td>\n",
       "      <td>E:\\Kuliah\\Pengenalan Pola\\addressing_agricultu...</td>\n",
       "      <td>Anthracnose</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>fixed300_bilinear</td>\n",
       "      <td>(5, 5)_sigma0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>hist_eq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>E:\\Kuliah\\Pengenalan Pola\\addressing_agricultu...</td>\n",
       "      <td>E:\\Kuliah\\Pengenalan Pola\\addressing_agricultu...</td>\n",
       "      <td>Anthracnose</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>fixed300_bilinear</td>\n",
       "      <td>(5, 5)_sigma0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>hist_eq</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>E:\\Kuliah\\Pengenalan Pola\\addressing_agricultu...</td>\n",
       "      <td>E:\\Kuliah\\Pengenalan Pola\\addressing_agricultu...</td>\n",
       "      <td>Anthracnose</td>\n",
       "      <td>1</td>\n",
       "      <td>300</td>\n",
       "      <td>300</td>\n",
       "      <td>fixed300_bilinear</td>\n",
       "      <td>(5, 5)_sigma0</td>\n",
       "      <td>1.2</td>\n",
       "      <td>hist_eq</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           orig_path  \\\n",
       "0  E:\\Kuliah\\Pengenalan Pola\\addressing_agricultu...   \n",
       "1  E:\\Kuliah\\Pengenalan Pola\\addressing_agricultu...   \n",
       "2  E:\\Kuliah\\Pengenalan Pola\\addressing_agricultu...   \n",
       "3  E:\\Kuliah\\Pengenalan Pola\\addressing_agricultu...   \n",
       "4  E:\\Kuliah\\Pengenalan Pola\\addressing_agricultu...   \n",
       "\n",
       "                                           prep_path        class  Output  \\\n",
       "0  E:\\Kuliah\\Pengenalan Pola\\addressing_agricultu...  Anthracnose       1   \n",
       "1  E:\\Kuliah\\Pengenalan Pola\\addressing_agricultu...  Anthracnose       1   \n",
       "2  E:\\Kuliah\\Pengenalan Pola\\addressing_agricultu...  Anthracnose       1   \n",
       "3  E:\\Kuliah\\Pengenalan Pola\\addressing_agricultu...  Anthracnose       1   \n",
       "4  E:\\Kuliah\\Pengenalan Pola\\addressing_agricultu...  Anthracnose       1   \n",
       "\n",
       "   width  height        resize_mode       gaussian  gamma equalization  \n",
       "0    300     300  fixed300_bilinear  (5, 5)_sigma0    1.2      hist_eq  \n",
       "1    300     300  fixed300_bilinear  (5, 5)_sigma0    1.2      hist_eq  \n",
       "2    300     300  fixed300_bilinear  (5, 5)_sigma0    1.2      hist_eq  \n",
       "3    300     300  fixed300_bilinear  (5, 5)_sigma0    1.2      hist_eq  \n",
       "4    300     300  fixed300_bilinear  (5, 5)_sigma0    1.2      hist_eq  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset from preprocessing index (keeps pipeline connected)\n",
    "if not INDEX_CSV.exists():\n",
    "    raise FileNotFoundError(f\"Index CSV not found: {INDEX_CSV}. Run preprocess notebook first.\")\n",
    "\n",
    "df = pd.read_csv(INDEX_CSV)\n",
    "\n",
    "# Backward-compatible column normalization\n",
    "# Expected: orig_path, prep_path, class, Output\n",
    "if \"orig_path\" not in df.columns:\n",
    "    if \"path\" in df.columns:\n",
    "        df[\"orig_path\"] = df[\"path\"]\n",
    "    else:\n",
    "        raise ValueError(f\"orig_path not found. Columns: {df.columns.tolist()}\")\n",
    "\n",
    "if \"class\" not in df.columns:\n",
    "    # try ClassName\n",
    "    if \"ClassName\" in df.columns:\n",
    "        df[\"class\"] = df[\"ClassName\"]\n",
    "    else:\n",
    "        df[\"class\"] = \"Unknown\"\n",
    "\n",
    "if \"Output\" not in df.columns:\n",
    "    # rebuild binary label if possible\n",
    "    df[\"Output\"] = df[\"class\"].astype(str).str.lower().apply(lambda x: 0 if x==\"healthy\" else 1)\n",
    "\n",
    "print(\"Loaded:\", INDEX_CSV)\n",
    "print(\"Rows:\", len(df))\n",
    "print(\"Counts per class:\")\n",
    "display(df[\"class\"].value_counts())\n",
    "\n",
    "print(\"\\nBinary counts (Output):\")\n",
    "display(df[\"Output\"].value_counts())\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bc0537d",
   "metadata": {},
   "source": [
    "K-Means Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb41c7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Annotation txt files found: 545\n"
     ]
    }
   ],
   "source": [
    "def kmeans_labels_lab(bgr, k=3):\n",
    "    lab = cv2.cvtColor(bgr, cv2.COLOR_BGR2LAB)\n",
    "    H, W = lab.shape[:2]\n",
    "    X = lab.reshape(-1, 3).astype(np.float32)\n",
    "\n",
    "    km = KMeans(n_clusters=k, random_state=RANDOM_STATE, n_init=\"auto\")\n",
    "    labels = km.fit_predict(X).reshape(H, W)\n",
    "    return labels\n",
    "\n",
    "def build_annot_index(annot_root: Path):\n",
    "    idx = {}\n",
    "    if not annot_root.exists():\n",
    "        return idx\n",
    "    for p in annot_root.rglob(\"*.txt\"):\n",
    "        idx[p.stem] = p\n",
    "    return idx\n",
    "\n",
    "ANNOT_INDEX = build_annot_index(ANNOT_DIR)\n",
    "print(\"Annotation txt files found:\", len(ANNOT_INDEX))\n",
    "\n",
    "def find_annotation_txt(img_path: str):\n",
    "    stem = Path(img_path).stem\n",
    "    return ANNOT_INDEX.get(stem, None)\n",
    "\n",
    "def parse_yolo_txt(txt_path: Path):\n",
    "    boxes = []\n",
    "    with open(txt_path, \"r\") as f:\n",
    "        for line in f:\n",
    "            line = line.strip()\n",
    "            if not line:\n",
    "                continue\n",
    "            parts = line.split()\n",
    "            if len(parts) != 5:\n",
    "                continue\n",
    "            cls = int(float(parts[0]))\n",
    "            xc, yc, bw, bh = map(float, parts[1:])\n",
    "            boxes.append((cls, xc, yc, bw, bh))\n",
    "    return boxes\n",
    "\n",
    "def yolo_to_xyxy(box, W, H):\n",
    "    _, xc, yc, bw, bh = box\n",
    "    x1 = (xc - bw/2) * W\n",
    "    y1 = (yc - bh/2) * H\n",
    "    x2 = (xc + bw/2) * W\n",
    "    y2 = (yc + bh/2) * H\n",
    "    x1 = int(max(0, round(x1))); y1 = int(max(0, round(y1)))\n",
    "    x2 = int(min(W-1, round(x2))); y2 = int(min(H-1, round(y2)))\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "def refine_roi_mask(mask01):\n",
    "    mask = (mask01 > 0).astype(np.uint8)\n",
    "    kernel = np.ones((7,7), np.uint8)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel, iterations=2)\n",
    "    mask = cv2.morphologyEx(mask, cv2.MORPH_OPEN,  kernel, iterations=1)\n",
    "\n",
    "    n, cc, stats, _ = cv2.connectedComponentsWithStats(mask*255, connectivity=8)\n",
    "    if n <= 1:\n",
    "        return mask\n",
    "    areas = stats[1:, cv2.CC_STAT_AREA]\n",
    "    idx = 1 + int(np.argmax(areas))\n",
    "    return (cc == idx).astype(np.uint8)\n",
    "\n",
    "def lesion_mask_from_txt(shape_hw, txt_path: Path):\n",
    "    H, W = shape_hw\n",
    "    mask = np.zeros((H, W), dtype=np.uint8)\n",
    "    boxes = parse_yolo_txt(txt_path)\n",
    "    for b in boxes:\n",
    "        x1, y1, x2, y2 = yolo_to_xyxy(b, W, H)\n",
    "        mask[y1:y2+1, x1:x2+1] = 1\n",
    "    return mask\n",
    "\n",
    "def bbox_from_mask(mask01: np.ndarray):\n",
    "    ys, xs = np.where(mask01 > 0)\n",
    "    if xs.size == 0:\n",
    "        return None\n",
    "    x1, x2 = int(xs.min()), int(xs.max())\n",
    "    y1, y2 = int(ys.min()), int(ys.max())\n",
    "    return x1, y1, x2, y2\n",
    "\n",
    "def clip_roi_to_lesion_context(roi_mask: np.ndarray, lesion_mask: np.ndarray, pad_ratio=0.35):\n",
    "    \"\"\"\n",
    "    Clip ROI agar hanya berada di area sekitar lesi (bbox + padding).\n",
    "    pad_ratio: 0.2-0.5 biasanya bagus. Makin besar = ROI makin luas.\n",
    "    \"\"\"\n",
    "    bb = bbox_from_mask(lesion_mask)\n",
    "    if bb is None:\n",
    "        return roi_mask\n",
    "\n",
    "    x1, y1, x2, y2 = bb\n",
    "    H, W = roi_mask.shape\n",
    "\n",
    "    bw = x2 - x1 + 1\n",
    "    bh = y2 - y1 + 1\n",
    "    pad_x = int(bw * pad_ratio)\n",
    "    pad_y = int(bh * pad_ratio)\n",
    "\n",
    "    X1 = max(0, x1 - pad_x); Y1 = max(0, y1 - pad_y)\n",
    "    X2 = min(W-1, x2 + pad_x); Y2 = min(H-1, y2 + pad_y)\n",
    "\n",
    "    clipped = np.zeros_like(roi_mask, dtype=np.uint8)\n",
    "    clipped[Y1:Y2+1, X1:X2+1] = roi_mask[Y1:Y2+1, X1:X2+1]\n",
    "    return clipped\n",
    "\n",
    "def border_touch_ratio(mask01: np.ndarray) -> float:\n",
    "    \"\"\"berapa proporsi pixel ROI yang menyentuh border\"\"\"\n",
    "    mask = (mask01 > 0).astype(np.uint8)\n",
    "    H, W = mask.shape\n",
    "    border = np.zeros_like(mask, dtype=np.uint8)\n",
    "    border[0,:]=1; border[-1,:]=1; border[:,0]=1; border[:,-1]=1\n",
    "    touch = int((mask & border).sum())\n",
    "    area = int(mask.sum()) + 1e-9\n",
    "    return float(touch / area)\n",
    "\n",
    "def score_roi(labels: np.ndarray, lesion_mask: np.ndarray, chosen):\n",
    "    \"\"\"\n",
    "    chosen: int atau list[int]\n",
    "    return dict score info\n",
    "    \"\"\"\n",
    "    if isinstance(chosen, int):\n",
    "        chosen = [chosen]\n",
    "\n",
    "    roi = np.zeros_like(labels, dtype=np.uint8)\n",
    "    for kk in chosen:\n",
    "        roi |= (labels == kk).astype(np.uint8)\n",
    "\n",
    "    lesion_area = int(lesion_mask.sum())\n",
    "    roi_area = int(roi.sum())\n",
    "    inter = int((roi & lesion_mask).sum())\n",
    "\n",
    "    if lesion_area == 0 or roi_area == 0 or inter == 0:\n",
    "        return {\"chosen\": chosen, \"f1\": 0.0, \"precision\": 0.0, \"recall\": 0.0, \"roi_area\": roi_area}\n",
    "\n",
    "    precision = inter / (roi_area + 1e-9)\n",
    "    recall = inter / (lesion_area + 1e-9)\n",
    "\n",
    "    # F1-score\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-9)\n",
    "\n",
    "    btr = border_touch_ratio(roi)\n",
    "    f1_adj = f1 * (1.0 - 0.35 * min(1.0, btr))  \n",
    "\n",
    "    return {\n",
    "        \"chosen\": chosen,\n",
    "        \"precision\": float(precision),\n",
    "        \"recall\": float(recall),\n",
    "        \"f1\": float(f1_adj),\n",
    "        \"roi_area\": int(roi_area),\n",
    "        \"inter\": int(inter),\n",
    "        \"border_touch\": float(btr)\n",
    "    }\n",
    "\n",
    "def pick_roi_clusters_robust(labels: np.ndarray, lesion_mask: np.ndarray):\n",
    "    \"\"\"\n",
    "    Coba:\n",
    "    - semua single cluster\n",
    "    - semua pasangan cluster (union)\n",
    "    pilih yang f1 terbaik\n",
    "    \"\"\"\n",
    "    k = int(labels.max()) + 1\n",
    "    best = None\n",
    "\n",
    "    for kk in range(k):\n",
    "        info = score_roi(labels, lesion_mask, kk)\n",
    "        if (best is None) or (info[\"f1\"] > best[\"f1\"]):\n",
    "            best = info\n",
    "\n",
    "    for a in range(k):\n",
    "        for b in range(a+1, k):\n",
    "            info = score_roi(labels, lesion_mask, [a, b])\n",
    "            if info[\"f1\"] > best[\"f1\"]:\n",
    "                best = info\n",
    "\n",
    "    return best \n",
    "\n",
    "def segment_guided_robust(bgr, txt_path: Path, pad_ratio=0.35):\n",
    "    labels = kmeans_labels_lab(bgr, k=3)\n",
    "    lesion_mask = lesion_mask_from_txt(labels.shape, txt_path)\n",
    "\n",
    "    if int(lesion_mask.sum()) == 0:\n",
    "        return labels, lesion_mask, None, None\n",
    "\n",
    "    best = pick_roi_clusters_robust(labels, lesion_mask)\n",
    "\n",
    "    if best is None or best[\"f1\"] <= 0:\n",
    "        return labels, lesion_mask, None, None\n",
    "\n",
    "    roi_mask = np.zeros_like(labels, dtype=np.uint8)\n",
    "    for kk in best[\"chosen\"]:\n",
    "        roi_mask |= (labels == kk).astype(np.uint8)\n",
    "\n",
    "    roi_mask = refine_roi_mask(roi_mask)\n",
    "\n",
    "    roi_mask = clip_roi_to_lesion_context(roi_mask, lesion_mask, pad_ratio=pad_ratio)\n",
    "\n",
    "    roi_mask = refine_roi_mask(roi_mask)\n",
    "\n",
    "    return labels, lesion_mask, roi_mask, best\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d240693a",
   "metadata": {},
   "source": [
    "Visualization & Save Samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5e41a03",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\User\\.conda\\envs\\pengenalan-pola\\Lib\\site-packages\\threadpoolctl.py:1226: RuntimeWarning: \n",
      "Found Intel OpenMP ('libiomp') and LLVM OpenMP ('libomp') loaded at\n",
      "the same time. Both libraries are known to be incompatible and this\n",
      "can cause random crashes or deadlocks on Linux when loaded in the\n",
      "same Python program.\n",
      "Using threadpoolctl may cause crashes or deadlocks. For more\n",
      "information and possible workarounds, please see\n",
      "    https://github.com/joblib/threadpoolctl/blob/master/multiple_openmp.md\n",
      "\n",
      "  warnings.warn(msg, RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved samples: 7\n",
      "Skipped (no annotation found): 5\n",
      "Output folder: E:\\Kuliah\\Pengenalan Pola\\addressing_agricultural_challenges\\outputs\\samples\\segmentation_guided\n"
     ]
    }
   ],
   "source": [
    "def bgr_to_rgb(bgr):\n",
    "    return cv2.cvtColor(bgr, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "def overlay_mask_on_bgr(bgr, mask, color=(0,0,255), alpha=0.35):\n",
    "    overlay = bgr.copy()\n",
    "    c = np.zeros_like(bgr)\n",
    "    c[:,:,:] = np.array(color, dtype=np.uint8)\n",
    "    overlay[mask==1] = (alpha*c[mask==1] + (1-alpha)*overlay[mask==1]).astype(np.uint8)\n",
    "    return overlay\n",
    "\n",
    "def prf_from_masks(roi_mask, lesion_mask):\n",
    "    roi = (roi_mask > 0).astype(np.uint8)\n",
    "    les = (lesion_mask > 0).astype(np.uint8)\n",
    "\n",
    "    inter = int((roi & les).sum())\n",
    "    roi_area = int(roi.sum())\n",
    "    les_area = int(les.sum())\n",
    "\n",
    "    if roi_area == 0 or les_area == 0 or inter == 0:\n",
    "        return 0.0, 0.0, 0.0\n",
    "\n",
    "    precision = inter / (roi_area + 1e-9)\n",
    "    recall = inter / (les_area + 1e-9)\n",
    "    f1 = 2 * precision * recall / (precision + recall + 1e-9)\n",
    "    return float(precision), float(recall), float(f1)\n",
    "\n",
    "\n",
    "def mask_to_3ch(mask01):\n",
    "    return (mask01 * 255).astype(np.uint8)\n",
    "    \n",
    "\n",
    "sample_n = 12\n",
    "sample_df = df.sample(min(sample_n, len(df)), random_state=RANDOM_STATE)\n",
    "\n",
    "saved = 0\n",
    "skipped_no_annot = 0\n",
    "\n",
    "for i, r in enumerate(sample_df.to_dict(\"records\"), start=1):\n",
    "    img_path = r.get(\"orig_path\", r.get(\"path\"))\n",
    "    bgr = read_bgr_300(img_path)\n",
    "    if bgr is None:\n",
    "        continue\n",
    "\n",
    "    txt = find_annotation_txt(img_path)\n",
    "    if txt is None:\n",
    "        skipped_no_annot += 1\n",
    "        continue\n",
    "\n",
    "    labels, lesion_mask, roi_mask, best = segment_guided_robust(bgr, txt)\n",
    "    if roi_mask is None:\n",
    "        continue\n",
    "\n",
    "    label_vis = (labels.astype(np.float32) / max(1, labels.max()) * 255).astype(np.uint8)\n",
    "    label_vis = cv2.applyColorMap(label_vis, cv2.COLORMAP_JET)\n",
    "\n",
    "    over_lesion = overlay_mask_on_bgr(bgr, lesion_mask, color=(0,255,255), alpha=0.35)  # yellow-ish\n",
    "    over_roi    = overlay_mask_on_bgr(bgr, roi_mask,    color=(0,0,255),   alpha=0.35)  # red\n",
    "\n",
    "    fig = plt.figure(figsize=(18, 4))\n",
    "    ax1 = fig.add_subplot(1, 4, 1)\n",
    "    ax2 = fig.add_subplot(1, 4, 2)\n",
    "    ax3 = fig.add_subplot(1, 4, 3)\n",
    "    ax4 = fig.add_subplot(1, 4, 4)\n",
    "\n",
    "    ax1.imshow(bgr_to_rgb(bgr))\n",
    "    ax1.set_title(f\"BGR 300x300 - {r['class']}\")\n",
    "    ax1.axis(\"off\")\n",
    "\n",
    "    ax2.imshow(bgr_to_rgb(label_vis))\n",
    "    ax2.set_title(\"KMeans (k=3) clusters (LAB)\")\n",
    "    ax2.axis(\"off\")\n",
    "\n",
    "    ax3.imshow(bgr_to_rgb(over_lesion))\n",
    "    ax3.set_title(\"Annotation lesion mask (YOLO)\")\n",
    "    ax3.axis(\"off\")\n",
    "\n",
    "    ax4.imshow(bgr_to_rgb(over_roi))\n",
    "    P2, R2, F12 = prf_from_masks(roi_mask, lesion_mask)\n",
    "    ax4.set_title(f\"ROI clusters={best['chosen']} | F1={F12:.2f} (P={P2:.2f}, R={R2:.2f})\")\n",
    "    ax4.axis(\"off\")\n",
    "\n",
    "    out_img = SAMPLE_DIR / f\"seg_{saved+1:02d}_{r['class']}.png\"\n",
    "    fig.savefig(out_img, bbox_inches=\"tight\")\n",
    "    plt.close(fig)\n",
    "    saved += 1\n",
    "\n",
    "print(\"Saved samples:\", saved)\n",
    "print(\"Skipped (no annotation found):\", skipped_no_annot)\n",
    "print(\"Output folder:\", SAMPLE_DIR)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pengenalan-pola",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
